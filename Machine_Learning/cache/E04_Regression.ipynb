{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Practical Machine Learning with Python\n",
    "\n",
    "## Guillermo Avendaño-Franco \n",
    "\n",
    "### HPC Summer Workshop 2019\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This material was elaborated from original notebooks for a class in Machine Learning at University of Turin. The original autors were Dr. Ciro Cattuto, Dr. Laetitia Gauvin and Dr. André Panisson. The material was adapted to fit the delivery format of a workshop on Practical Machine Learning on Python for graduate students and Faculty at West Virginia University. The original notebooks can be downloaded from [Rugantio Costa's Github Repository](https://github.com/rugantio/MachineLearningCourse.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These data points will be used in the exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 1.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 9.]\n",
      " [10.]]\n",
      "y =  [[3.76405235]\n",
      " [3.20015721]\n",
      " [4.57873798]\n",
      " [6.6408932 ]\n",
      " [7.06755799]\n",
      " [5.02272212]\n",
      " [7.75008842]\n",
      " [7.44864279]\n",
      " [8.29678115]\n",
      " [9.6105985 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = 10 # training examples\n",
    "x = np.linspace(1, 10, m).reshape(m, 1)\n",
    "y = np.array([ 3.76405235,  3.20015721,  4.57873798,  6.6408932 ,  7.06755799,\n",
    "        5.02272212,  7.75008842,  7.44864279,  8.29678115,  9.6105985 ]).reshape(m, 1)\n",
    "\n",
    "print ('x = ', x)\n",
    "print ('y = ', y)\n",
    "\n",
    "plt.plot(x, y, 'bx');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the data points for matrix manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      " [[ 1.  1.]\n",
      " [ 1.  2.]\n",
      " [ 1.  3.]\n",
      " [ 1.  4.]\n",
      " [ 1.  5.]\n",
      " [ 1.  6.]\n",
      " [ 1.  7.]\n",
      " [ 1.  8.]\n",
      " [ 1.  9.]\n",
      " [ 1. 10.]]\n",
      "Y = \n",
      " [[3.76405235]\n",
      " [3.20015721]\n",
      " [4.57873798]\n",
      " [6.6408932 ]\n",
      " [7.06755799]\n",
      " [5.02272212]\n",
      " [7.75008842]\n",
      " [7.44864279]\n",
      " [8.29678115]\n",
      " [9.6105985 ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.insert(x, 0, np.ones(len(x)), axis=1)\n",
    "Y = np.array(y).reshape(m, 1)\n",
    "\n",
    "print ('X = \\n', X)\n",
    "print ('Y = \\n', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Ordinary Least Squares\n",
    "\n",
    "Find the weight values $\\mathbf{w}$ that minimize the error $E_{\\mathbf{in}}(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^n {(\\mathbf{w}^T \\mathbf{X}_n - \\mathbf{y}_n)^2}$.\n",
    "\n",
    "For this, implement Linear Regression and use the Ordinary Least Squares (OLS) closed-form expression to find the estimated values of $\\mathbf{w}$:\n",
    "\n",
    "$$\\mathbf{w} = (\\mathbf{X}^{\\rm T}\\mathbf{X})^{-1} \\mathbf{X}^{\\rm T}\\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "print ('w = \\n', w)\n",
    "\n",
    "p = plot (X[:,1], Y, 'bx')\n",
    "p = plot (X[:,1], X.dot(w), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Batch Gradient Descent\n",
    "\n",
    "Find the weight values $\\mathbf{w}$ that minimize the error $E_{\\mathbf{in}}(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^n {(\\mathbf{w}^T \\mathbf{X}_n - \\mathbf{y}_n)^2}$.\n",
    "\n",
    "For this, implement the Batch Gradient Descent algorithm with $\\mathbf{s}$ learning steps and learning rate $\\alpha$.  \n",
    "At each training step, update $\\mathbf{w}$ with this rule:\n",
    "\n",
    "$$\\mathbf{w}_i := \\mathbf{w}_i - \\alpha \\left(\\left(\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\right)^T\\mathbf{X}_i\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = X.shape\n",
    "s = 1000 # learning steps\n",
    "alpha = 0.001 # learning rate\n",
    "\n",
    "w = zeros(d).reshape(d, 1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print (w)\n",
    "\n",
    "p = plot (X[:,1], Y, 'bx')\n",
    "p = plot (X[:,1], X.dot(w), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Stochastic Gradient Descent\n",
    "\n",
    "Find the weight values $\\mathbf{w}$ that minimize the error $E_{\\mathbf{in}}(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^n {(\\mathbf{w}^T \\mathbf{X}_n - \\mathbf{y}_n)^2}$.\n",
    "\n",
    "For this, implement the Stochastic Gradient Descent algorithm with $\\mathbf{s}$ learning steps and learning rate $\\alpha$.\n",
    "In each step, iterate through all $j$ samples and, for each sample, update $\\mathbf{w}$ with this rule:\n",
    "\n",
    "$$\\mathbf{w}_i := \\mathbf{w}_i - \\alpha\\left(\\mathbf{X}^{(j)}\\mathbf{w} - \\mathbf{y}^{(j)}\\right)\\mathbf{X}^{(j)}_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = X.shape\n",
    "s = 1000 # learning steps\n",
    "alpha = 0.001 # learning rate\n",
    "\n",
    "w = zeros(d).reshape(d, 1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print (w)\n",
    "\n",
    "p = plot (X[:,1], Y, 'bx')\n",
    "p = plot (X[:,1], X.dot(w), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: write a function fit(X,Y) \n",
    "\n",
    "The function fit(X,Y) receives a matrix $X \\in \\mathbb{R}^{m,n}$, where m is the number of samples and n is the number of features, and a matrix $Y \\in \\mathbb{R}^{m}$, and returns the matrix of coefficients $\\mathbf{w} \\in \\mathbb{R}^{n+1}$.   \n",
    "Implement the function with Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, Y):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it!\n",
    "\n",
    "m = 10\n",
    "x = linspace(1, m, m).reshape(m,1)\n",
    "y = array([ 3.76405235,  3.20015721,  4.57873798,  6.6408932 ,  7.06755799,\n",
    "        5.02272212,  7.75008842,  7.44864279,  8.29678115,  9.6105985 ]).reshape(m,1)\n",
    "\n",
    "w = fit(x,y)\n",
    "\n",
    "print ('w = \\n', w)\n",
    "\n",
    "p = plot (X[:,1], Y, 'bx')\n",
    "p = plot (X[:,1], X.dot(w), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scikit-Learn for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if Scikit-Learn is installed in your system. If not, install it.\n",
    "\n",
    "Resources and documentation: http://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: find the coefficients $\\mathbf{w}$ using sklearn.linear_model.LinearRegression\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "x = linspace(1, m, m)\n",
    "y = array([ 3.76405235,  3.20015721,  4.57873798,  6.6408932 ,  7.06755799,\n",
    "        5.02272212,  7.75008842,  7.44864279,  8.29678115,  9.6105985 ])\n",
    "x.shape = (m,1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print ('Coefficients = ', model.coef_, ', Intercept = ', model.intercept_)\n",
    "# compare the results to the Ordinary Least Squares result!\n",
    "\n",
    "p = plot (x, y, 'bx')\n",
    "p = plot (x, x*model.coef_+model.intercept_, 'r-')\n",
    "p = plot (x, model.predict(x), 'go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: find the coefficients $\\mathbf{w}$ using sklearn.linear_model.Lasso\n",
    "\n",
    "Regularization introduces a penalty in the model complexity, in order to prevent overfitting.  \n",
    "Lasso (least absolute shrinkage and selection operator) uses the constraint that $\\|\\mathbf{w}\\|_1$, the L1-norm of the parameter vector, is no greater than a given value.  \n",
    "The optimization objective for Lasso is:\n",
    "$$ \\frac{1}{2n} \\|\\mathbf{Xw} - \\mathbf{y}\\|^2_2 + \\alpha\\|\\mathbf{w}\\|_1$$\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "Lasso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "x = linspace(1, m, m)\n",
    "y = array([ 3.76405235,  3.20015721,  4.57873798,  6.6408932 ,  7.06755799,\n",
    "        5.02272212,  7.75008842,  7.44864279,  8.29678115,  9.6105985 ])\n",
    "x.shape = (m,1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print ('Coefficients = ', model.coef_, ', Intercept = ', model.intercept_)\n",
    "# compare the results to the Ordinary Least Squares result!\n",
    "\n",
    "p = plot (x, y, 'bx')\n",
    "p = plot (x, x*model.coef_+model.intercept_, 'r-')\n",
    "p = plot (x, model.predict(x), 'go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the Boston house-prices dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset and print the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print (boston.DESCR)\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a plot for each feature, to have an idea of their correlation with the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,20))\n",
    "nr_plots = len(boston.feature_names)-1\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Create a Regression model using Scikit-Learn Linear Regression for the Boston house-prices dataset\n",
    "\n",
    "Use sklearn.linear_model.LinearRegression to predict the target variable y using only the average number of rooms (RM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X[:,[5]]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plot(Xtrain, y, 'bx', label='true data')\n",
    "plot(Xtrain, pred, 'gx', label='predicted')\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Train and Test sets\n",
    "\n",
    "Let's split our dataset in the Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_cases = y.shape[0]\n",
    "nTrain = np.floor(nr_cases *2.0 / 3.0)\n",
    "import random\n",
    "ids = list(range(nr_cases))\n",
    "random.shuffle(ids)\n",
    "\n",
    "trainX,trainY,testX,testY = [],[],[],[]\n",
    "for i, idx in enumerate(ids):\n",
    "    if i < nTrain:\n",
    "        trainX.append(X[idx, [5]])\n",
    "        trainY.append(y[idx])\n",
    "    else:\n",
    "        testX.append(X[idx, [5]])\n",
    "        testY.append(y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Calculate the MAE and RMSE\n",
    "\n",
    "Use only the samples in the training set to train your regression model (use sklearn.linear_model.LinearRegression).\n",
    "\n",
    "Predict the values for the samples in the test set and calculate the **mean absolute error (MAE)** and the **root-mean-square error (RMSE)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(testY, predY):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "def rmse(testY, predY):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# Train a Linear Regression model using only train data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Predict the test values using the model\n",
    "predY = model.predict(testX)\n",
    "\n",
    "print(mae(testY, predY))\n",
    "print(rmse(testY, predY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: Train with all features\n",
    "\n",
    "Split the Boston house-prices dataset into Training and Test sets, but using all features. Train a regression model with all features, calculate the MAE and RMSE and compare it with the previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_cases = y.shape[0]\n",
    "nTrain = np.floor(nr_cases *2.0 / 3.0)\n",
    "import random\n",
    "ids = list(range(nr_cases))\n",
    "random.shuffle(ids)\n",
    "\n",
    "trainX,trainY,testX,testY = [],[],[],[]\n",
    "for i, idx in enumerate(ids):\n",
    "    if i < nTrain:\n",
    "        trainX.append(X[idx])\n",
    "        trainY.append(y[idx])\n",
    "    else:\n",
    "        testX.append(X[idx])\n",
    "        testY.append(y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(testY, predY):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "def rmse(testY, predY):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# Train a Linear Regression model using only train data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Predict the test values using the model\n",
    "predY = model.predict(testX)\n",
    "\n",
    "print(mae(testY, predY))\n",
    "print(rmse(testY, predY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
