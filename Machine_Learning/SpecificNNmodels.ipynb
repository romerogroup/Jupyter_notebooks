{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, I will build a series of sections based on the mas actual topics on deep learning. I will try to give examples and show how we can use these new methods. As this is an on going project, I will try to work on my free time. Which is not very free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are neural networks that work directly on a graph.\n",
    "\n",
    "A graph is a structure consisting of two components, vertices and edges. A graph G can be well described by the set of vertices V and edges E it contains. In computer science a single datastructure can be created for such purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative adversarial networks (GANs) are deep neural net architectures comprised of two nets, pitting one against the other (thus the “adversarial”). Introduced in 2014 by Goodfellow and other people. \n",
    "\n",
    "GANs’ potential is huge, because they can learn to mimic any distribution of data. That is, GANs can be taught to create worlds eerily similar to our own in any domain: images, music, speech, prose. To understand GANs, you should know how generative algorithms work. Up to now, most of the algorithms we have discussed are the so called discriminative algorithms, where we try to predict the output from a given set of features. In the Bayesian language, we are trying to predict $P(c_j|x_1,x_2,\\cdots,x_n)$. In GANs, we are concern a different idea,\n",
    "we try to features given a certain label. Therefore, here we would like to build $P(x_1,x_2,\\cdots,x_n | c_j)$.\n",
    "\n",
    "The idea in GANs then is to have two neural networks. One is called the generator, which generates features and the other network, the discriminator evaluates its authenticity, i.e. the discriminator decides whether each instance of data that it reviews belongs to the actual training dataset or not. For example is we try to analyze a book from a great author (for example Garcia Marquez). We could analyze the language used in his texts but for this example, the generator should be able to create words and the discriminator should be able to recognize if this are authentic. The idea of the generator then is to create words that were not originally created by Garcia Marquez but that the discriminator is unable to distinguish.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
